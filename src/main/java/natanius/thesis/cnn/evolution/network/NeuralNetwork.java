package natanius.thesis.cnn.evolution.network;

import java.util.ArrayList;
import java.util.List;
import lombok.Getter;
import natanius.thesis.cnn.evolution.data.Image;
import natanius.thesis.cnn.evolution.layers.ConvolutionLayer;
import natanius.thesis.cnn.evolution.layers.FullyConnectedLayer;
import natanius.thesis.cnn.evolution.layers.Layer;
import natanius.thesis.cnn.evolution.layers.MaxPoolLayer;

public class NeuralNetwork {
    @Getter
    private final List<Layer> layers;

    private static final String RESET = "\u001B[0m";
    private static final String CYAN = "\u001B[36m";     // Titles
    private static final String GREEN = "\u001B[32m";    // Convolution
    private static final String BLUE = "\u001B[34m";     // Max Pooling
    private static final String MAGENTA = "\u001B[35m";  // Fully Connected
    private static final String YELLOW = "\u001B[33m";   // Stats

    public NeuralNetwork(List<Layer> layers) {
        this.layers = layers;
        linkLayers();
    }

    public void linkLayers() {
        if (layers.size() <= 1) {
            return;
        }

        for (int i = 0; i < layers.size(); i++) {
            if (i == 0) {
                layers.get(i).setNextLayer(layers.get(i + 1));
            } else if (i == layers.size() - 1) {
                layers.get(i).setPreviousLayer(layers.get(i - 1));
            } else {
                layers.get(i).setPreviousLayer(layers.get(i - 1));
                layers.get(i).setNextLayer(layers.get(i + 1));
            }
        }
    }

    /**
     * –ó–∞—Å—Ç–æ—Å–æ–≤—É—î Softmax –¥–æ –≤–µ–∫—Ç–æ—Ä–∞ logits –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π.
     *
     * @param logits –≤–∏—Ö—ñ–¥–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –∑ –æ—Å—Ç–∞–Ω–Ω—å–æ–≥–æ —à–∞—Ä—É
     * @return –≤–µ–∫—Ç–æ—Ä –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π (—Å—É–º–∞ = 1.0)
     */
    private double[] applySoftmax(double[] logits) {
        // –î–ª—è —á–∏—Å–ª–æ–≤–æ—ó —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ –≤—ñ–¥–Ω—ñ–º–∞—î–º–æ –º–∞–∫—Å–∏–º—É–º
        double max = logits[0];
        for (int i = 1; i < logits.length; i++) {
            if (logits[i] > max) max = logits[i];
        }

        double[] exp = new double[logits.length];
        double sum = 0.0;

        for (int i = 0; i < logits.length; i++) {
            exp[i] = Math.exp(logits[i] - max);
            sum += exp[i];
        }

        for (int i = 0; i < logits.length; i++) {
            exp[i] /= sum;
        }

        return exp;
    }

    /**
     * –û–±—á–∏—Å–ª—é—î –≥—Ä–∞–¥—ñ—î–Ω—Ç Cross-Entropy Loss –∑ Softmax.
     * –î–ª—è Softmax + Cross-Entropy –≥—Ä–∞–¥—ñ—î–Ω—Ç —Å–ø—Ä–æ—â—É—î—Ç—å—Å—è –¥–æ: output - target
     *
     * @param networkOutput –≤–∏—Ö—ñ–¥ –º–µ—Ä–µ–∂—ñ –ø—ñ—Å–ª—è Softmax (–π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ)
     * @param correctAnswer –ø—Ä–∞–≤–∏–ª—å–Ω–∞ –º—ñ—Ç–∫–∞ –∫–ª–∞—Å—É (0-9)
     * @return –≥—Ä–∞–¥—ñ—î–Ω—Ç loss function
     */
    private double[] getErrors(double[] networkOutput, int correctAnswer) {
        int numClasses = networkOutput.length;
        double[] expected = new double[numClasses];
        expected[correctAnswer] = 1;  // One-hot encoding

        double[] errors = new double[numClasses];
        for (int i = 0; i < numClasses; i++) {
            errors[i] = networkOutput[i] - expected[i];  // output - target
        }
        return errors;
    }


    private double computeCrossEntropyLoss(double[] output, int correctLabel) {
        double eps = 1e-7;
        return -Math.log(Math.max(output[correctLabel], eps));
    }


    private int getMaxIndex(double[] in) {
        double max = 0;
        int index = 0;

        for (int i = 0; i < in.length; i++) {
            if (in[i] >= max) {
                max = in[i];
                index = i;
            }
        }

        return index;
    }

    /**
     * –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (–æ–¥–∏–Ω–æ—á–Ω–µ)
     * –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î batch size = 1 –¥–ª—è inference
     */
    public int guess(Image image) {
        List<List<double[][]>> batchInputs = new ArrayList<>();
        List<double[][]> imgList = new ArrayList<>();
        imgList.add(image.data());
        batchInputs.add(imgList);

        // Forward —á–µ—Ä–µ–∑ –≤–µ—Å—å –±–∞—Ç—á (—Ä–æ–∑–º—ñ—Ä 1)
        List<double[]> batchOutputs = layers.getFirst().getOutputBatch(batchInputs);

        double[] output = batchOutputs.getFirst();
        double[] softmaxOut = applySoftmax(output);
        return getMaxIndex(softmaxOut);
    }

    /**
     * –ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –¥–ª—è –±–∞—Ç—á—É –∑–æ–±—Ä–∞–∂–µ–Ω—å
     */
    public List<Integer> guessBatch(List<Image> images) {
        List<Integer> predictions = new ArrayList<>();

        List<List<double[][]>> batchInputs = new ArrayList<>();
        for (Image img : images) {
            List<double[][]> imgList = new ArrayList<>();
            imgList.add(img.data());
            batchInputs.add(imgList);
        }

        List<double[]> batchOutputs = layers.getFirst().getOutputBatch(batchInputs);

        for (double[] output : batchOutputs) {
            double[] softmaxOut = applySoftmax(output);
            predictions.add(getMaxIndex(softmaxOut));
        }

        return predictions;
    }

    /**
     * Real-time prediction –¥–ª—è –æ–¥–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ (784 –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ –¥–ª—è MNIST)
     */
    public double[] guessInRealTime(double[] inputs) {
        double[][] inputMatrix = new double[28][28];

        for (int i = 0; i < 28; i++) {
            System.arraycopy(inputs, i * 28, inputMatrix[i], 0, 28);
        }

        List<List<double[][]>> batchInputs = new ArrayList<>();
        List<double[][]> imgList = new ArrayList<>();
        imgList.add(inputMatrix);
        batchInputs.add(imgList);

        List<double[]> batchOutputs = layers.getFirst().getOutputBatch(batchInputs);

        double[] output = batchOutputs.getFirst();
        return applySoftmax(output);  // –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ
    }



    public float test(List<Image> images) {
        int correct = 0;
        int size = images.size();

        for (Image img : images) {
            int guess = guess(img);
            if (guess == img.label()) {
                correct++;
            }
        }

        return ((float) correct / size);
    }

    /**
     * –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–∞ –±–∞—Ç—á–∞—Ö (–±—ñ–ª—å—à –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –Ω–∞–±–æ—Ä—ñ–≤)
     */
    public float testBatch(List<Image> images, int batchSize) {
        int correct = 0;
        int numBatches = (images.size() + batchSize - 1) / batchSize;

        for (int b = 0; b < numBatches; b++) {
            int start = b * batchSize;
            int end = Math.min(start + batchSize, images.size());
            List<Image> batch = images.subList(start, end);

            List<Integer> predictions = guessBatch(batch);

            for (int i = 0; i < predictions.size(); i++) {
                if (predictions.get(i) == batch.get(i).label()) {
                    correct++;
                }
            }
        }

        return ((float) correct / images.size());
    }

    /**
     * –ù–∞–≤—á–∞–Ω–Ω—è –Ω–∞ –æ–¥–Ω—ñ–π –µ–ø–æ—Å—ñ –∑ mini-batch —Ä–æ–∑–±–∏—Ç—Ç—è–º
     *
     * @param images    —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏–π –Ω–∞–±—ñ—Ä
     * @param batchSize —Ä–æ–∑–º—ñ—Ä –±–∞—Ç—á–∞
     */
    public void trainEpoch(List<Image> images, int batchSize) {
        int numBatches = (images.size() + batchSize - 1) / batchSize;
        double totalLoss = 0.0;

        for (int b = 0; b < numBatches; b++) {
            int start = b * batchSize;
            int end = Math.min(start + batchSize, images.size());
            List<Image> batch = images.subList(start, end);

            List<List<double[][]>> batchInputs = new ArrayList<>();
            List<Integer> labels = new ArrayList<>();

            for (Image img : batch) {
                List<double[][]> imgList = new ArrayList<>();
                imgList.add(img.data());
                batchInputs.add(imgList);
                labels.add(img.label());
            }

            // Forward —á–µ—Ä–µ–∑ –≤—Å—é –º–µ—Ä–µ–∂—É
            List<double[]> batchOutputs = layers.getFirst().getOutputBatch(batchInputs);

            List<double[]> batchErrors = new ArrayList<>();
            double batchLoss = 0.0;

            for (int i = 0; i < batch.size(); i++) {
                double[] output = batchOutputs.get(i);
                double[] softmaxOut = applySoftmax(output);

                // –û–±—á–∏—Å–ª—é—î–º–æ loss –¥–ª—è —Ü—å–æ–≥–æ –ø—Ä–∏–∫–ª–∞–¥—É
                double loss = computeCrossEntropyLoss(softmaxOut, labels.get(i));
                batchLoss += loss;

                // –û–±—á–∏—Å–ª—é—î–º–æ –≥—Ä–∞–¥—ñ—î–Ω—Ç (Softmax + CrossEntropy)
                double[] errors = getErrors(softmaxOut, labels.get(i));
                batchErrors.add(errors);
            }

            totalLoss += batchLoss;

            layers.getLast().backPropagationBatch(batchErrors);
        }
    }


    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder();

        sb.append(CYAN).append("\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n");
        sb.append("‚ïë ").append(centerText("üß† NEURAL NETWORK ARCHITECTURE üß†", 81)).append(" ‚ïë\n");
        sb.append("‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n").append(RESET);

        int totalParams = 0;

        for (int i = 0; i < layers.size(); i++) {
            Layer layer = layers.get(i);
            totalParams += layer.getParameterCount();

            String color;
            if (layer instanceof ConvolutionLayer) {
                color = GREEN;
            } else if (layer instanceof MaxPoolLayer) {
                color = BLUE;
            } else {
                color = (layer instanceof FullyConnectedLayer) ? MAGENTA : RESET;
            }

            sb.append(color).append("‚ïë ").append(centerText(layer.toString(), 82)).append(" ‚ïë\n").append(RESET);

            if (i < layers.size() - 1) {
                sb.append("‚ïë                                        ‚ñº                                           ‚ïë\n");
            }
        }

        sb.append("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n");
        sb.append(YELLOW).append("üìä Total Layers: ").append(layers.size())
            .append(" | Total Parameters: ").append(totalParams).append(RESET).append("\n");

        return sb.toString();
    }

    private String centerText(String text, int width) {
        int padding = Math.max(0, (width - text.length()));
        int leftPadding = padding / 2;
        int rightPadding = padding - leftPadding;

        return " ".repeat(leftPadding) + text + " ".repeat(rightPadding);
    }
}
